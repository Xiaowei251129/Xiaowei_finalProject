{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "478ee2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /opt/anaconda3/lib/python3.13/site-packages (4.6.0)\n",
      "Requirement already satisfied: xgboost in /opt/anaconda3/lib/python3.13/site-packages (3.1.2)\n",
      "Requirement already satisfied: lightgbm in /opt/anaconda3/lib/python3.13/site-packages (4.6.0)\n",
      "Requirement already satisfied: mlflow<3 in /opt/anaconda3/lib/python3.13/site-packages (2.22.4)\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.13/site-packages (1.1.0)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.13/site-packages (1.4.2)\n",
      "Requirement already satisfied: mlflow-skinny==2.22.4 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (2.22.4)\n",
      "Requirement already satisfied: Flask<4 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (3.1.0)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (3.1.6)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (1.16.4)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (3.4.3)\n",
      "Requirement already satisfied: gunicorn<24 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (23.0.0)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (3.8)\n",
      "Requirement already satisfied: matplotlib<4 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (3.10.0)\n",
      "Requirement already satisfied: numpy<3 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (2.1.3)\n",
      "Requirement already satisfied: pandas!=2.3.0,<3 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (2.2.3)\n",
      "Requirement already satisfied: pyarrow<20,>=4.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (19.0.0)\n",
      "Requirement already satisfied: scikit-learn<2 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (1.6.1)\n",
      "Requirement already satisfied: scipy<2 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (1.15.3)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (2.0.39)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (5.5.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (8.1.8)\n",
      "Requirement already satisfied: cloudpickle<4 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (3.0.0)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (0.74.0)\n",
      "Requirement already satisfied: fastapi<1 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (0.124.4)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (3.1.43)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (8.5.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (1.39.1)\n",
      "Requirement already satisfied: packaging<25 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (24.2)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (6.33.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (2.10.3)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (2.32.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (0.5.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (4.12.2)\n",
      "Requirement already satisfied: uvicorn<1 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (0.38.0)\n",
      "Requirement already satisfied: Mako in /opt/anaconda3/lib/python3.13/site-packages (from alembic!=1.10.0,<2->mlflow<3) (1.2.3)\n",
      "Requirement already satisfied: google-auth~=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.4->mlflow<3) (2.43.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/anaconda3/lib/python3.13/site-packages (from docker<8,>=4.0.0->mlflow<3) (2.3.0)\n",
      "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /opt/anaconda3/lib/python3.13/site-packages (from fastapi<1->mlflow-skinny==2.22.4->mlflow<3) (0.50.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /opt/anaconda3/lib/python3.13/site-packages (from fastapi<1->mlflow-skinny==2.22.4->mlflow<3) (0.0.4)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in /opt/anaconda3/lib/python3.13/site-packages (from Flask<4->mlflow<3) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /opt/anaconda3/lib/python3.13/site-packages (from Flask<4->mlflow<3) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in /opt/anaconda3/lib/python3.13/site-packages (from Flask<4->mlflow<3) (1.9.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/lib/python3.13/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.22.4->mlflow<3) (4.0.7)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/anaconda3/lib/python3.13/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.22.4->mlflow<3) (4.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.13/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.4->mlflow<3) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.13/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.4->mlflow<3) (4.9.1)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /opt/anaconda3/lib/python3.13/site-packages (from graphene<4->mlflow<3) (3.2.7)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /opt/anaconda3/lib/python3.13/site-packages (from graphene<4->mlflow<3) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /opt/anaconda3/lib/python3.13/site-packages (from graphene<4->mlflow<3) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/anaconda3/lib/python3.13/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.4->mlflow<3) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from Jinja2<4,>=2.11->mlflow<3) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib<4->mlflow<3) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib<4->mlflow<3) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib<4->mlflow<3) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib<4->mlflow<3) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib<4->mlflow<3) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib<4->mlflow<3) (3.2.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /opt/anaconda3/lib/python3.13/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.4->mlflow<3) (0.60b1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas!=2.3.0,<3->mlflow<3) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas!=2.3.0,<3->mlflow<3) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.4->mlflow<3) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.4->mlflow<3) (2.27.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow<3) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.4->mlflow<3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.4->mlflow<3) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.4->mlflow<3) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/anaconda3/lib/python3.13/site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.4->mlflow<3) (0.4.8)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn<2->mlflow<3) (3.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /opt/anaconda3/lib/python3.13/site-packages (from starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.4->mlflow<3) (4.7.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.13/site-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.4->mlflow<3) (1.3.0)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/anaconda3/lib/python3.13/site-packages (from uvicorn<1->mlflow-skinny==2.22.4->mlflow<3) (0.16.0)\n",
      "Requirement already satisfied: colorlog in /opt/anaconda3/lib/python3.13/site-packages (from optuna) (6.10.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.13/site-packages (from optuna) (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna xgboost lightgbm \"mlflow<3\" python-dotenv joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73c0a905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chengxiaowei/Desktop/Python/eas503/Xiaowei_finalProject\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_folder = \"/Users/chengxiaowei/Desktop/Python/eas503/Xiaowei_finalProject\"\n",
    "%cd \"{base_folder}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39c599f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flight_id</th>\n",
       "      <th>date</th>\n",
       "      <th>schedtime</th>\n",
       "      <th>deptime</th>\n",
       "      <th>distance</th>\n",
       "      <th>flightnumber</th>\n",
       "      <th>weather</th>\n",
       "      <th>dayweek</th>\n",
       "      <th>daymonth</th>\n",
       "      <th>carrier</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>tailnu</th>\n",
       "      <th>delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1/1/2004</td>\n",
       "      <td>1455</td>\n",
       "      <td>1455</td>\n",
       "      <td>184</td>\n",
       "      <td>5935</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>OH</td>\n",
       "      <td>BWI</td>\n",
       "      <td>JFK</td>\n",
       "      <td>N940CA</td>\n",
       "      <td>ontime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2004</td>\n",
       "      <td>1640</td>\n",
       "      <td>1640</td>\n",
       "      <td>213</td>\n",
       "      <td>6155</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>DH</td>\n",
       "      <td>DCA</td>\n",
       "      <td>JFK</td>\n",
       "      <td>N405FJ</td>\n",
       "      <td>ontime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1/1/2004</td>\n",
       "      <td>1245</td>\n",
       "      <td>1245</td>\n",
       "      <td>229</td>\n",
       "      <td>7208</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>DH</td>\n",
       "      <td>IAD</td>\n",
       "      <td>LGA</td>\n",
       "      <td>N695BR</td>\n",
       "      <td>ontime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1/1/2004</td>\n",
       "      <td>1715</td>\n",
       "      <td>1709</td>\n",
       "      <td>229</td>\n",
       "      <td>7215</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>DH</td>\n",
       "      <td>IAD</td>\n",
       "      <td>LGA</td>\n",
       "      <td>N662BR</td>\n",
       "      <td>ontime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1/1/2004</td>\n",
       "      <td>1039</td>\n",
       "      <td>1035</td>\n",
       "      <td>229</td>\n",
       "      <td>7792</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>DH</td>\n",
       "      <td>IAD</td>\n",
       "      <td>LGA</td>\n",
       "      <td>N698BR</td>\n",
       "      <td>ontime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   flight_id      date  schedtime  deptime  distance  flightnumber  weather  \\\n",
       "0          0  1/1/2004       1455     1455       184          5935        0   \n",
       "1          1  1/1/2004       1640     1640       213          6155        0   \n",
       "2          2  1/1/2004       1245     1245       229          7208        0   \n",
       "3          3  1/1/2004       1715     1709       229          7215        0   \n",
       "4          4  1/1/2004       1039     1035       229          7792        0   \n",
       "\n",
       "   dayweek  daymonth carrier origin dest  tailnu   delay  \n",
       "0        4         1      OH    BWI  JFK  N940CA  ontime  \n",
       "1        4         1      DH    DCA  JFK  N405FJ  ontime  \n",
       "2        4         1      DH    IAD  LGA  N695BR  ontime  \n",
       "3        4         1      DH    IAD  LGA  N662BR  ontime  \n",
       "4        4         1      DH    IAD  LGA  N698BR  ontime  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "db_path = f\"{base_folder}/xiaowei_data/flightdelays.db\"   # <<< 改成你的db位置\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "df = pd.read_sql_query(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "      f.flight_id,\n",
    "      f.date,\n",
    "      f.schedtime,\n",
    "      f.deptime,\n",
    "      f.distance,\n",
    "      f.flightnumber,\n",
    "      f.weather,\n",
    "      f.dayweek,\n",
    "      f.daymonth,\n",
    "      c.code AS carrier,\n",
    "      a1.code AS origin,\n",
    "      a2.code AS dest,\n",
    "      t.tailnu AS tailnu,\n",
    "      f.delay\n",
    "    FROM flight f\n",
    "    JOIN dim_carrier c ON f.carrier_id = c.carrier_id\n",
    "    JOIN dim_airport a1 ON f.origin_airport_id = a1.airport_id\n",
    "    JOIN dim_airport a2 ON f.dest_airport_id = a2.airport_id\n",
    "    JOIN dim_tail t ON f.tail_id = t.tail_id\n",
    "    ORDER BY f.flight_id\n",
    "    \"\"\",\n",
    "    conn,\n",
    ")\n",
    "conn.close()\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087575a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "import joblib\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.base import clone\n",
    "\n",
    "from flightdelays_pipeline import build_preprocessing, make_estimator_for_name\n",
    "\n",
    "start_time = time.monotonic()\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7090bdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ STEP 1: Preprocessing pipeline created.\n"
     ]
    }
   ],
   "source": [
    "# def build_preprocessing():\n",
    "#     num_features = [\"schedtime\", \"distance\", \"weather\", \"dayweek\", \"daymonth\", \"flightnumber\"]\n",
    "#     cat_features = [\"carrier\", \"origin\", \"dest\"]\n",
    "\n",
    "#     numeric_transformer = Pipeline(steps=[\n",
    "#         (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "#         (\"scaler\", StandardScaler()),\n",
    "#     ])\n",
    "\n",
    "#     categorical_transformer = Pipeline(steps=[\n",
    "#         (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "#         (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "#     ])\n",
    "\n",
    "#     return ColumnTransformer(\n",
    "#         transformers=[\n",
    "#             (\"num\", numeric_transformer, num_features),\n",
    "#             (\"cat\", categorical_transformer, cat_features),\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "preprocessing = build_preprocessing()\n",
    "print(\"✓ STEP 1: Preprocessing pipeline created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aef8b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ STEP 2: Stratified split done. Train size: 1760, Test size: 441\n",
      "Class balance: {0: 1773, 1: 428}\n"
     ]
    }
   ],
   "source": [
    "# y: delayed=1, ontime=0\n",
    "y = df[\"delay\"].map({\"ontime\": 0, \"delayed\": 1}).astype(int)\n",
    "\n",
    "X = df[\n",
    "    [\"schedtime\", \"distance\", \"weather\", \"dayweek\", \"daymonth\", \"flightnumber\",\n",
    "     \"carrier\", \"origin\", \"dest\"]\n",
    "].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    stratify=y,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"✓ STEP 2: Stratified split done. Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
    "print(\"Class balance:\", y.value_counts().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9039566f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/14 11:47:50 INFO mlflow.tracking.fluent: Experiment with name 'flightdelays_multi_model_optuna' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ STEP 3: MLflow configured.\n"
     ]
    }
   ],
   "source": [
    "# 如果你没有 .env，先注释掉 load_dotenv 和 set_tracking_uri，只保留 set_experiment\n",
    "# load_dotenv(dotenv_path=f\"{base_folder}/notebooks/.env\", override=True)\n",
    "\n",
    "# MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "# if MLFLOW_TRACKING_URI:\n",
    "#     mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "mlflow.set_experiment(\"flightdelays_multi_model_optuna\")\n",
    "print(\"✓ STEP 3: MLflow configured.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4f74fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "def objective_ridge(trial, preprocessing, X_train, y_train):\n",
    "    alpha = trial.suggest_float(\"ridge__alpha\", 0.1, 100.0, log=True)\n",
    "    preprocessing_clone = clone(preprocessing)\n",
    "    pipeline = make_pipeline(preprocessing_clone, RidgeClassifier(alpha=alpha, class_weight=\"balanced\"))\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
    "    return scores.mean()  # maximize\n",
    "\n",
    "\n",
    "def objective_hgb(trial, preprocessing, X_train, y_train):\n",
    "    learning_rate = trial.suggest_float(\"hgb__learning_rate\", 0.02, 0.3, log=True)\n",
    "    max_depth = trial.suggest_int(\"hgb__max_depth\", 2, 10)\n",
    "    preprocessing_clone = clone(preprocessing)\n",
    "    pipeline = make_pipeline(\n",
    "        preprocessing_clone,\n",
    "        HistGradientBoostingClassifier(\n",
    "            learning_rate=learning_rate,\n",
    "            max_depth=max_depth,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "    )\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
    "    return scores.mean()\n",
    "\n",
    "\n",
    "def objective_xgb(trial, preprocessing, X_train, y_train):\n",
    "    learning_rate = trial.suggest_float(\"xgb__learning_rate\", 0.01, 0.3, log=True)\n",
    "    max_depth = trial.suggest_int(\"xgb__max_depth\", 2, 10)\n",
    "    n_estimators = trial.suggest_int(\"xgb__n_estimators\", 200, 1200, step=100)\n",
    "    subsample = trial.suggest_float(\"xgb__subsample\", 0.6, 1.0)\n",
    "    colsample = trial.suggest_float(\"xgb__colsample_bytree\", 0.6, 1.0)\n",
    "\n",
    "    preprocessing_clone = clone(preprocessing)\n",
    "    pipeline = make_pipeline(\n",
    "        preprocessing_clone,\n",
    "        XGBClassifier(\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_estimators=n_estimators,\n",
    "            learning_rate=learning_rate,\n",
    "            max_depth=max_depth,\n",
    "            subsample=subsample,\n",
    "            colsample_bytree=colsample,\n",
    "            eval_metric=\"logloss\",\n",
    "            tree_method=\"hist\",\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "    )\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
    "    return scores.mean()\n",
    "\n",
    "\n",
    "def objective_lgbm(trial, preprocessing, X_train, y_train):\n",
    "    learning_rate = trial.suggest_float(\"lgbm__learning_rate\", 0.01, 0.3, log=True)\n",
    "    num_leaves = trial.suggest_int(\"lgbm__num_leaves\", 15, 255)\n",
    "    n_estimators = trial.suggest_int(\"lgbm__n_estimators\", 200, 2000, step=200)\n",
    "\n",
    "    preprocessing_clone = clone(preprocessing)\n",
    "    pipeline = make_pipeline(\n",
    "        preprocessing_clone,\n",
    "        LGBMClassifier(\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_estimators=n_estimators,\n",
    "            learning_rate=learning_rate,\n",
    "            num_leaves=num_leaves,\n",
    "            n_jobs=-1,\n",
    "            verbose=-1,\n",
    "        )\n",
    "    )\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
    "    return scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4785c49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Optimizing RIDGE (NO PCA) - 10 trials\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd166e55ebe8443bae078f01051a7ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best RIDGE CV F1: 0.4027\n",
      "Best params: {'ridge__alpha': 0.14936568554617632}\n",
      "ridge (no PCA) Test F1: 0.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Optimizing HISTGRADIENTBOOSTING (NO PCA) - 10 trials\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'ridge_pipeline_optuna' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'ridge_pipeline_optuna'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4e63d4cf5c4070b42eeda30ee237ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best HISTGRADIENTBOOSTING CV F1: 0.4291\n",
      "Best params: {'hgb__learning_rate': 0.10185822566867639, 'hgb__max_depth': 8}\n",
      "histgradientboosting (no PCA) Test F1: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Optimizing XGBOOST (NO PCA) - 10 trials\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'histgradientboosting_pipeline_optuna' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'histgradientboosting_pipeline_optuna'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0109d9931346a892b77992bc632568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best XGBOOST CV F1: 0.4662\n",
      "Best params: {'xgb__learning_rate': 0.14447746112718687, 'xgb__max_depth': 3, 'xgb__n_estimators': 700, 'xgb__subsample': 0.836965827544817, 'xgb__colsample_bytree': 0.6185801650879991}\n",
      "xgboost (no PCA) Test F1: 0.4768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Optimizing LIGHTGBM (NO PCA) - 10 trials\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'xgboost_pipeline_optuna' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'xgboost_pipeline_optuna'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4fdf5aa9ff74bc3b82d5601aaa2d5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LIGHTGBM CV F1: 0.4563\n",
      "Best params: {'lgbm__learning_rate': 0.07661100707771368, 'lgbm__num_leaves': 52, 'lgbm__n_estimators': 400}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm (no PCA) Test F1: 0.4503\n",
      "\n",
      "✓ STEP 5: All 4 baseline models optimized and logged.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "Registered model 'lightgbm_pipeline_optuna' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'lightgbm_pipeline_optuna'.\n"
     ]
    }
   ],
   "source": [
    "model_names = [\"ridge\", \"histgradientboosting\", \"xgboost\", \"lightgbm\"]\n",
    "objective_functions = {\n",
    "    \"ridge\": objective_ridge,\n",
    "    \"histgradientboosting\": objective_hgb,\n",
    "    \"xgboost\": objective_xgb,\n",
    "    \"lightgbm\": objective_lgbm,\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name in model_names:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Optimizing {name.upper()} (NO PCA) - 10 trials\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        sampler=TPESampler(seed=RANDOM_STATE),\n",
    "        study_name=f\"{name}_study\"\n",
    "    )\n",
    "\n",
    "    study.optimize(\n",
    "        lambda trial: objective_functions[name](trial, preprocessing, X_train, y_train),\n",
    "        n_trials=10,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    cv_f1 = float(study.best_value)\n",
    "    best_params = study.best_params\n",
    "\n",
    "    print(f\"\\nBest {name.upper()} CV F1: {cv_f1:.4f}\")\n",
    "    print(f\"Best params: {best_params}\")\n",
    "\n",
    "    preprocessing_clone = clone(preprocessing)\n",
    "\n",
    "    if name == \"ridge\":\n",
    "        final_model = make_pipeline(preprocessing_clone, RidgeClassifier(alpha=best_params[\"ridge__alpha\"], class_weight=\"balanced\"))\n",
    "    elif name == \"histgradientboosting\":\n",
    "        final_model = make_pipeline(\n",
    "            preprocessing_clone,\n",
    "            HistGradientBoostingClassifier(\n",
    "                learning_rate=best_params[\"hgb__learning_rate\"],\n",
    "                max_depth=best_params[\"hgb__max_depth\"],\n",
    "                random_state=RANDOM_STATE\n",
    "            )\n",
    "        )\n",
    "    elif name == \"xgboost\":\n",
    "        final_model = make_pipeline(\n",
    "            preprocessing_clone,\n",
    "            XGBClassifier(\n",
    "                random_state=RANDOM_STATE,\n",
    "                n_estimators=best_params[\"xgb__n_estimators\"],\n",
    "                learning_rate=best_params[\"xgb__learning_rate\"],\n",
    "                max_depth=best_params[\"xgb__max_depth\"],\n",
    "                subsample=best_params[\"xgb__subsample\"],\n",
    "                colsample_bytree=best_params[\"xgb__colsample_bytree\"],\n",
    "                eval_metric=\"logloss\",\n",
    "                tree_method=\"hist\",\n",
    "                n_jobs=-1,\n",
    "            )\n",
    "        )\n",
    "    elif name == \"lightgbm\":\n",
    "        final_model = make_pipeline(\n",
    "            preprocessing_clone,\n",
    "            LGBMClassifier(\n",
    "                random_state=RANDOM_STATE,\n",
    "                n_estimators=best_params[\"lgbm__n_estimators\"],\n",
    "                learning_rate=best_params[\"lgbm__learning_rate\"],\n",
    "                num_leaves=best_params[\"lgbm__num_leaves\"],\n",
    "                n_jobs=-1,\n",
    "                verbose=-1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    final_model.fit(X_train, y_train)\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    test_f1 = float(f1_score(y_test, y_pred))\n",
    "\n",
    "    print(f\"{name} (no PCA) Test F1: {test_f1:.4f}\")\n",
    "\n",
    "    results[name] = {\"pipeline\": final_model, \"test_f1\": test_f1, \"cv_f1\": cv_f1}\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"{name}_baseline_optuna\"):\n",
    "        mlflow.log_param(\"model_family\", name)\n",
    "        mlflow.log_param(\"uses_pca\", False)\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_metric(\"cv_F1\", cv_f1)\n",
    "        mlflow.log_metric(\"test_F1\", test_f1)\n",
    "\n",
    "        signature = infer_signature(X_train, final_model.predict(X_train))\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=final_model,\n",
    "            artifact_path=\"flightdelays_model\",\n",
    "            signature=signature,\n",
    "            input_example=X_train,\n",
    "            registered_model_name=f\"{name}_pipeline_optuna\",\n",
    "        )\n",
    "\n",
    "print(\"\\n✓ STEP 5: All 4 baseline models optimized and logged.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a170f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1033bdbc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x106c61bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x106b2dbc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1067d5bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x107f3dbc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x104409bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x102465bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x106ba9bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    }
   ],
   "source": [
    "def objective_ridge_pca(trial, preprocessing, X_train, y_train):\n",
    "    alpha = trial.suggest_float(\"ridge__alpha\", 0.1, 100.0, log=True)\n",
    "    pca_components = trial.suggest_float(\"pca__n_components\", 0.90, 0.99)\n",
    "    preprocessing_clone = clone(preprocessing)\n",
    "    pipeline = make_pipeline(preprocessing_clone, PCA(n_components=pca_components), RidgeClassifier(alpha=alpha, class_weight=\"balanced\"))\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
    "    return scores.mean()\n",
    "\n",
    "def objective_hgb_pca(trial, preprocessing, X_train, y_train):\n",
    "    learning_rate = trial.suggest_float(\"hgb__learning_rate\", 0.02, 0.3, log=True)\n",
    "    max_depth = trial.suggest_int(\"hgb__max_depth\", 2, 10)\n",
    "    pca_components = trial.suggest_float(\"pca__n_components\", 0.90, 0.99)\n",
    "    preprocessing_clone = clone(preprocessing)\n",
    "    pipeline = make_pipeline(\n",
    "        preprocessing_clone,\n",
    "        PCA(n_components=pca_components),\n",
    "        HistGradientBoostingClassifier(\n",
    "            learning_rate=learning_rate, max_depth=max_depth, random_state=RANDOM_STATE\n",
    "        )\n",
    "    )\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
    "    return scores.mean()\n",
    "\n",
    "def objective_xgb_pca(trial, preprocessing, X_train, y_train):\n",
    "    learning_rate = trial.suggest_float(\"xgb__learning_rate\", 0.01, 0.3, log=True)\n",
    "    max_depth = trial.suggest_int(\"xgb__max_depth\", 2, 10)\n",
    "    n_estimators = trial.suggest_int(\"xgb__n_estimators\", 200, 1200, step=100)\n",
    "    subsample = trial.suggest_float(\"xgb__subsample\", 0.6, 1.0)\n",
    "    colsample = trial.suggest_float(\"xgb__colsample_bytree\", 0.6, 1.0)\n",
    "    pca_components = trial.suggest_float(\"pca__n_components\", 0.90, 0.99)\n",
    "\n",
    "    preprocessing_clone = clone(preprocessing)\n",
    "    pipeline = make_pipeline(\n",
    "        preprocessing_clone,\n",
    "        PCA(n_components=pca_components),\n",
    "        XGBClassifier(\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_estimators=n_estimators,\n",
    "            learning_rate=learning_rate,\n",
    "            max_depth=max_depth,\n",
    "            subsample=subsample,\n",
    "            colsample_bytree=colsample,\n",
    "            eval_metric=\"logloss\",\n",
    "            tree_method=\"hist\",\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "    )\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
    "    return scores.mean()\n",
    "\n",
    "def objective_lgbm_pca(trial, preprocessing, X_train, y_train):\n",
    "    learning_rate = trial.suggest_float(\"lgbm__learning_rate\", 0.01, 0.3, log=True)\n",
    "    num_leaves = trial.suggest_int(\"lgbm__num_leaves\", 15, 255)\n",
    "    n_estimators = trial.suggest_int(\"lgbm__n_estimators\", 200, 2000, step=200)\n",
    "    pca_components = trial.suggest_float(\"pca__n_components\", 0.90, 0.99)\n",
    "\n",
    "    preprocessing_clone = clone(preprocessing)\n",
    "    pipeline = make_pipeline(\n",
    "        preprocessing_clone,\n",
    "        PCA(n_components=pca_components),\n",
    "        LGBMClassifier(\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_estimators=n_estimators,\n",
    "            learning_rate=learning_rate,\n",
    "            num_leaves=num_leaves,\n",
    "            n_jobs=-1,\n",
    "            verbose=-1,\n",
    "        )\n",
    "    )\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
    "    return scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d28e9fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Optimizing RIDGE_WITH_PCA - 10 trials\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a78da60d57e448591f3a725273eca20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best RIDGE_WITH_PCA CV F1: 0.3785\n",
      "Best params: {'ridge__alpha': 6.358358856676251, 'pca__n_components': 0.963726532001644}\n",
      "ridge_with_pca Test F1: 0.3902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Optimizing HISTGRADIENTBOOSTING_WITH_PCA - 10 trials\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'ridge_pipeline_with_pca_optuna' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'ridge_pipeline_with_pca_optuna'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "508bf463d3414e31a9eddbfc2310d298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best HISTGRADIENTBOOSTING_WITH_PCA CV F1: 0.3381\n",
      "Best params: {'hgb__learning_rate': 0.06877172495876589, 'hgb__max_depth': 9, 'pca__n_components': 0.9179706403942524}\n",
      "histgradientboosting_with_pca Test F1: 0.3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Optimizing XGBOOST_WITH_PCA - 10 trials\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'histgradientboosting_pipeline_with_pca_optuna' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'histgradientboosting_pipeline_with_pca_optuna'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9883d1cfeff147bcbb50af67079ad680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best XGBOOST_WITH_PCA CV F1: 0.3543\n",
      "Best params: {'xgb__learning_rate': 0.04717052037625178, 'xgb__max_depth': 9, 'xgb__n_estimators': 400, 'xgb__subsample': 0.8056937753654446, 'xgb__colsample_bytree': 0.836965827544817, 'pca__n_components': 0.9041805371447998}\n",
      "xgboost_with_pca Test F1: 0.4242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Optimizing LIGHTGBM_WITH_PCA - 10 trials\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'xgboost_pipeline_with_pca_optuna' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'xgboost_pipeline_with_pca_optuna'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed86b42399de4a5d92b490cec90c24d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LIGHTGBM_WITH_PCA CV F1: 0.3603\n",
      "Best params: {'lgbm__learning_rate': 0.08012737503998542, 'lgbm__num_leaves': 48, 'lgbm__n_estimators': 600, 'pca__n_components': 0.9329725658964323}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm_with_pca Test F1: 0.4085\n",
      "\n",
      "✓ STEP 7: All 4 PCA models optimized and logged.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "Registered model 'lightgbm_pipeline_with_pca_optuna' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'lightgbm_pipeline_with_pca_optuna'.\n"
     ]
    }
   ],
   "source": [
    "pca_model_names = [\"ridge_with_pca\", \"histgradientboosting_with_pca\", \"xgboost_with_pca\", \"lightgbm_with_pca\"]\n",
    "pca_objective_functions = {\n",
    "    \"ridge_with_pca\": objective_ridge_pca,\n",
    "    \"histgradientboosting_with_pca\": objective_hgb_pca,\n",
    "    \"xgboost_with_pca\": objective_xgb_pca,\n",
    "    \"lightgbm_with_pca\": objective_lgbm_pca,\n",
    "}\n",
    "\n",
    "pca_results = {}\n",
    "\n",
    "for name in pca_model_names:\n",
    "    base_name = name.replace(\"_with_pca\", \"\")\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Optimizing {name.upper()} - 10 trials\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        sampler=TPESampler(seed=RANDOM_STATE),\n",
    "        study_name=f\"{name}_study\"\n",
    "    )\n",
    "\n",
    "    study.optimize(\n",
    "        lambda trial: pca_objective_functions[name](trial, preprocessing, X_train, y_train),\n",
    "        n_trials=10,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    cv_f1 = float(study.best_value)\n",
    "    best_params = study.best_params\n",
    "\n",
    "    print(f\"\\nBest {name.upper()} CV F1: {cv_f1:.4f}\")\n",
    "    print(f\"Best params: {best_params}\")\n",
    "\n",
    "    preprocessing_clone = clone(preprocessing)\n",
    "    pca_n = best_params[\"pca__n_components\"]\n",
    "\n",
    "    if base_name == \"ridge\":\n",
    "        final_model = make_pipeline(preprocessing_clone, PCA(n_components=pca_n), RidgeClassifier(alpha=best_params[\"ridge__alpha\"], class_weight=\"balanced\"))\n",
    "    elif base_name == \"histgradientboosting\":\n",
    "        final_model = make_pipeline(\n",
    "            preprocessing_clone,\n",
    "            PCA(n_components=pca_n),\n",
    "            HistGradientBoostingClassifier(\n",
    "                learning_rate=best_params[\"hgb__learning_rate\"],\n",
    "                max_depth=best_params[\"hgb__max_depth\"],\n",
    "                random_state=RANDOM_STATE\n",
    "            )\n",
    "        )\n",
    "    elif base_name == \"xgboost\":\n",
    "        final_model = make_pipeline(\n",
    "            preprocessing_clone,\n",
    "            PCA(n_components=pca_n),\n",
    "            XGBClassifier(\n",
    "                random_state=RANDOM_STATE,\n",
    "                n_estimators=best_params[\"xgb__n_estimators\"],\n",
    "                learning_rate=best_params[\"xgb__learning_rate\"],\n",
    "                max_depth=best_params[\"xgb__max_depth\"],\n",
    "                subsample=best_params[\"xgb__subsample\"],\n",
    "                colsample_bytree=best_params[\"xgb__colsample_bytree\"],\n",
    "                eval_metric=\"logloss\",\n",
    "                tree_method=\"hist\",\n",
    "                n_jobs=-1,\n",
    "            )\n",
    "        )\n",
    "    elif base_name == \"lightgbm\":\n",
    "        final_model = make_pipeline(\n",
    "            preprocessing_clone,\n",
    "            PCA(n_components=pca_n),\n",
    "            LGBMClassifier(\n",
    "                random_state=RANDOM_STATE,\n",
    "                n_estimators=best_params[\"lgbm__n_estimators\"],\n",
    "                learning_rate=best_params[\"lgbm__learning_rate\"],\n",
    "                num_leaves=best_params[\"lgbm__num_leaves\"],\n",
    "                n_jobs=-1,\n",
    "                verbose=-1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    final_model.fit(X_train, y_train)\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    test_f1 = float(f1_score(y_test, y_pred))\n",
    "\n",
    "    print(f\"{name} Test F1: {test_f1:.4f}\")\n",
    "\n",
    "    pca_results[name] = {\"pipeline\": final_model, \"test_f1\": test_f1, \"cv_f1\": cv_f1}\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"{name}_optuna\"):\n",
    "        mlflow.log_param(\"model_family\", base_name)\n",
    "        mlflow.log_param(\"uses_pca\", True)\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_metric(\"cv_F1\", cv_f1)\n",
    "        mlflow.log_metric(\"test_F1\", test_f1)\n",
    "\n",
    "        signature = infer_signature(X_train, final_model.predict(X_train))\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=final_model,\n",
    "            artifact_path=\"flightdelays_model_with_pca\",\n",
    "            signature=signature,\n",
    "            input_example=X_train,\n",
    "            registered_model_name=f\"{base_name}_pipeline_with_pca_optuna\",\n",
    "        )\n",
    "\n",
    "print(\"\\n✓ STEP 7: All 4 PCA models optimized and logged.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82b01b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GLOBAL BEST MODEL (ACROSS 8 CANDIDATES)\n",
      "================================================================================\n",
      "Global best model key: xgboost\n",
      "Global best CV F1:     0.4662\n",
      "Global best Test F1:   0.4768\n",
      "Uses PCA:              False\n"
     ]
    }
   ],
   "source": [
    "all_results = {}\n",
    "all_results.update(results)\n",
    "all_results.update(pca_results)\n",
    "\n",
    "global_best_name = max(all_results, key=lambda k: all_results[k][\"test_f1\"])\n",
    "global_best_test_f1 = all_results[global_best_name][\"test_f1\"]\n",
    "global_best_cv_f1 = all_results[global_best_name][\"cv_f1\"]\n",
    "global_best_pipeline = all_results[global_best_name][\"pipeline\"]\n",
    "\n",
    "uses_pca = \"with_pca\" in global_best_name\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GLOBAL BEST MODEL (ACROSS 8 CANDIDATES)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Global best model key: {global_best_name}\")\n",
    "print(f\"Global best CV F1:     {global_best_cv_f1:.4f}\")\n",
    "print(f\"Global best Test F1:   {global_best_test_f1:.4f}\")\n",
    "print(f\"Uses PCA:              {uses_pca}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adf6db46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model saved to /Users/chengxiaowei/Desktop/Python/eas503/Xiaowei_finalProject/models/global_best_flightdelays_optuna.pkl\n",
      "Elapsed time: 16 minutes and 52.85 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x102e21bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1046f1bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1050cdbc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x102c6dbc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x102c21bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x104a25bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x102e0dbc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x104e1dbc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    }
   ],
   "source": [
    "def save_model(model, filename):\n",
    "    joblib.dump(model, filename)\n",
    "    print(f\"✓ Model saved to {filename}\")\n",
    "\n",
    "save_path = f\"{base_folder}/models/global_best_flightdelays_optuna.pkl\"\n",
    "save_model(global_best_pipeline, filename=save_path)\n",
    "\n",
    "end_time = time.monotonic()\n",
    "elapsed_time = end_time - start_time\n",
    "minutes = int(elapsed_time // 60)\n",
    "seconds = elapsed_time % 60\n",
    "print(f\"Elapsed time: {minutes} minutes and {seconds:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2382935d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
